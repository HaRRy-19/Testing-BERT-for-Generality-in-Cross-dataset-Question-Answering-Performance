{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvalVarGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWikuE_jfMIz",
        "outputId": "e98fbe4b-0dff-4dfd-eb81-d968fee6e9a4"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install tokenizers\n",
        "import tensorflow as tf\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ8yVatwfsgM",
        "outputId": "f96dd45a-0569-4518-ae5e-9eddcad6fa53"
      },
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-mKDpX0f7La"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUpYuuWSf_2P"
      },
      "source": [
        "# ============================================= PREPARING DATASET ======================================================\n",
        "class Sample:\n",
        "    def __init__(self, question, context, id, start_char_idx=None, answer_text=None, all_answers=None):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "        self.start_token_idx = -1\n",
        "        self.end_token_idx = -1\n",
        "        self.id = id\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = \" \".join(str(self.context).split())\n",
        "        question = \" \".join(str(self.question).split())\n",
        "        tokenized_context = tokenizer.encode(context)\n",
        "        tokenized_question = tokenizer.encode(question)\n",
        "        if self.answer_text is not None:\n",
        "            answer = \" \".join(str(self.answer_text).split())\n",
        "            end_char_idx = self.start_char_idx + len(answer)\n",
        "            if end_char_idx >= len(context):\n",
        "                self.skip = True\n",
        "                return\n",
        "            is_char_in_ans = [0] * len(context)\n",
        "            for idx in range(self.start_char_idx, end_char_idx):\n",
        "                is_char_in_ans[idx] = 1\n",
        "            ans_token_idx = []\n",
        "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "                if sum(is_char_in_ans[start:end]) > 0:\n",
        "                    ans_token_idx.append(idx)\n",
        "            if len(ans_token_idx) == 0:\n",
        "                self.skip = True\n",
        "                return\n",
        "            self.start_token_idx = ans_token_idx[0]\n",
        "            self.end_token_idx = ans_token_idx[-1]\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if padding_length > 0:\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "        self.input_word_ids = input_ids\n",
        "        self.input_type_ids = token_type_ids\n",
        "        self.input_mask = attention_mask\n",
        "        self.context_token_to_char = tokenized_context.offsets\n",
        "\n",
        "\n",
        "def create_squad_examples(raw_data, excludeAnswers = False):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                id = qa[\"id\"]\n",
        "                if \"answers\" in qa and not excludeAnswers:\n",
        "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                    \n",
        "                    squad_eg = Sample(question, context, id, start_char_idx, answer_text, all_answers)\n",
        "                else:\n",
        "                    squad_eg = Sample(question, context, id)\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_word_ids\": [],\n",
        "        \"input_type_ids\": [],\n",
        "        \"input_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "    x = [dataset_dict[\"input_word_ids\"],\n",
        "         dataset_dict[\"input_mask\"],\n",
        "         dataset_dict[\"input_type_ids\"]]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5LLT_5pgCNK"
      },
      "source": [
        "# =================================================== TRAINING =========================================================\n",
        "\n",
        "\n",
        "class ValidationCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        text = re.sub(regex, \" \", text)\n",
        "        text = \" \".join(text.split())\n",
        "        return text\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
        "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBiRMM5vgHKp"
      },
      "source": [
        "train_path = keras.utils.get_file(\"train.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
        "eval_path = keras.utils.get_file(\"eval.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
        "with open(train_path) as f: raw_train_data = json.load(f)\n",
        "with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "max_seq_length = 512"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0mjpLeUgQ7r",
        "outputId": "d55102d6-26b6-4b3e-8d4a-ee59860b5ccd"
      },
      "source": [
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
        "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
        "#train_squad_examples = create_squad_examples(raw_train_data)\n",
        "#x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "#print(f\"{len(train_squad_examples)} training points created.\")\n",
        "#eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "#x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "#print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
        "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
        "start_logits = layers.Flatten()(start_logits)\n",
        "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
        "end_logits = layers.Flatten()(end_logits)\n",
        "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "model.summary()\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights(\"/content/gdrive/My Drive/TrainingResults/SQUAD2.0SeqLength512.h5\")\n",
        "\n",
        "\n",
        "# model.fit(x_train, y_train, epochs=2, batch_size=8, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
        "# model.save_weights(\"/content/gdrive/My Drive/TrainingResults/weights.h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 512, 1)       768         keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 512, 1)       768         keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 512)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 512)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,777\n",
            "Trainable params: 109,483,776\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojHFG267g_A4",
        "outputId": "a2825b38-5d76-4c7d-ed07-595ed5175eb7"
      },
      "source": [
        "# ==================================================== TESTING =========================================================\n",
        "data = {\"data\":\n",
        "    [\n",
        "        {\"title\": \"Project Apollo\",\n",
        "         \"paragraphs\": [\n",
        "             {\n",
        "                 \"context\": \"The Apollo program, also known as Project Apollo, was the third United States human \"\n",
        "                            \"spaceflight program carried out by the National Aeronautics and Space Administration (\"\n",
        "                            \"NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First \"\n",
        "                            \"conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to \"\n",
        "                            \"follow the one-man Project Mercury which put the first Americans in space, Apollo was \"\n",
        "                            \"later dedicated to President John F. Kennedy's national goal of landing a man on the \"\n",
        "                            \"Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in \"\n",
        "                            \"a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project \"\n",
        "                            \"Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, \"\n",
        "                            \"and was supported by the two man Gemini program which ran concurrently with it from 1962 \"\n",
        "                            \"to 1966. Gemini missions developed some of the space travel techniques that were \"\n",
        "                            \"necessary for the success of the Apollo missions. Apollo used Saturn family rockets as \"\n",
        "                            \"launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications \"\n",
        "                            \"Program, which consisted of Skylab, a space station that supported three manned missions \"\n",
        "                            \"in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the \"\n",
        "                            \"Soviet Union in 1975.\",\n",
        "                 \"qas\": [\n",
        "                     {\"question\": \"What project put the first Americans into space?\",\n",
        "                      \"id\": \"Q1\"\n",
        "                      },\n",
        "                     {\"question\": \"What program was created to carry out these projects and missions?\",\n",
        "                      \"id\": \"Q2\"\n",
        "                      },\n",
        "                     {\"question\": \"What year did the first manned Apollo flight occur?\",\n",
        "                      \"id\": \"Q3\"\n",
        "                      },\n",
        "                     {\"question\": \"What President is credited with the original notion of putting Americans in space?\",\n",
        "                      \"id\": \"Q4\"\n",
        "                      },\n",
        "                     {\"question\": \"Who did the U.S. collaborate with on an Earth orbit mission in 1975?\",\n",
        "                      \"id\": \"Q5\"\n",
        "                      },\n",
        "                     {\"question\": \"How long did Project Apollo run?\",\n",
        "                      \"id\": \"Q6\"\n",
        "                      },\n",
        "                     {\"question\": \"What program helped develop space travel techniques that Project Apollo used?\",\n",
        "                      \"id\": \"Q7\"\n",
        "                      },\n",
        "                     {\"question\": \"What space station supported three manned missions in 1973-1974?\",\n",
        "                      \"id\": \"Q8\"\n",
        "                      },\n",
        "                      {\"question\": \"Trees?\",\n",
        "                      \"id\": \"Q9\"\n",
        "                      }\n",
        "                 ]}]}]}\n",
        "\n",
        "test_samples = create_squad_examples(data)\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model.predict(x_test)\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "    test_sample = test_samples[idx]\n",
        "    offsets = test_sample.context_token_to_char\n",
        "    start = np.argmax(start)\n",
        "    end = np.argmax(end)\n",
        "    pred_ans = None\n",
        "    if start >= len(offsets):\n",
        "        continue\n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "        pred_ans = test_sample.context[pred_char_start:]\n",
        "    print(\"Q: \" + test_sample.question)\n",
        "    print(\"A: \" + pred_ans)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What project put the first Americans into space?\n",
            "A: Project Mercury\n",
            "Q: What program was created to carry out these projects and missions?\n",
            "A: Apollo\n",
            "Q: What year did the first manned Apollo flight occur?\n",
            "A: 1968\n",
            "Q: What President is credited with the original notion of putting Americans in space?\n",
            "A: John F. Kennedy\n",
            "Q: Who did the U.S. collaborate with on an Earth orbit mission in 1975?\n",
            "A: Soviet Union\n",
            "Q: How long did Project Apollo run?\n",
            "A: 1961 to 1972\n",
            "Q: What program helped develop space travel techniques that Project Apollo used?\n",
            "A: Gemini\n",
            "Q: What space station supported three manned missions in 1973-1974?\n",
            "A: Skylab\n",
            "Q: Trees?\n",
            "A: The Apollo program\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTx_yvUiqCb"
      },
      "source": [
        "# ==================================================== ORIGINAL TESTING =========================================================\n",
        "\n",
        "test_samples = create_squad_examples(data)\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model.predict(x_test)\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "    test_sample = test_samples[idx]\n",
        "    offsets = test_sample.context_token_to_char\n",
        "    start = np.argmax(start)\n",
        "    end = np.argmax(end)\n",
        "    pred_ans = None\n",
        "    if start >= len(offsets):\n",
        "        continue\n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "        pred_ans = test_sample.context[pred_char_start:]\n",
        "    test_sample.answer_text = pred_ans\n",
        "    test_sample.start_char_idx = pred_char_start\n",
        "    # print(\"Q: \" + test_sample.question)\n",
        "    # print(\"A: \" + pred_ans)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W70LrfDUrS6C"
      },
      "source": [
        "def samples_to_predictions(samples):\n",
        "  results = {}\n",
        "  for sample in samples:\n",
        "    if (sample.start_char_idx == -1): # Question predicted as unanswerable\n",
        "      results[sample.id] = \"\"\n",
        "    else:\n",
        "      results[sample.id] = sample.answer_text\n",
        "  return results"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjqDKan5z2me",
        "outputId": "7b715ea0-f9f5-4f05-d96b-cf5deabd74e9"
      },
      "source": [
        "print(samples_to_predictions(test_samples))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Q1': 'Project Mercury', 'Q2': 'Apollo', 'Q3': '1968', 'Q4': 'John F. Kennedy', 'Q5': 'Soviet Union', 'Q6': '1961 to 1972', 'Q7': 'Gemini', 'Q8': 'Skylab', 'Q9': 'The Apollo program'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5uTOocmwr1j"
      },
      "source": [
        "def samples_to_squad_json(samples):\n",
        "  ContextQuestionPairs = {}\n",
        "  for sample in samples:\n",
        "    QAPair = {}\n",
        "    QAPair[\"id\"] = sample.id\n",
        "    QAPair[\"question\"] = sample.question\n",
        "    QAPair[\"answers\"] = []\n",
        "    if (sample.start_char_idx == -1):\n",
        "      QAPair[\"is_impossible\"] = True\n",
        "    else:  \n",
        "      QAPair[\"answers\"].append({\"text\":sample.answer_text, \"answer_start\":sample.start_char_idx })\n",
        "      QAPair[\"is_impossible\"] = False\n",
        "    if sample.context in ContextQuestionPairs:\n",
        "      ContextQuestionPairs[sample.context].append(QAPair)\n",
        "    else:\n",
        "      qas = [QAPair]\n",
        "      ContextQuestionPairs[sample.context] = qas\n",
        "  \n",
        "  raw_data={}\n",
        "  data = []\n",
        "  \n",
        "  for context, qas in ContextQuestionPairs.items():\n",
        "    data.append({\"title\": \"\", \"paragraphs\": [{\"context\": context, \"qas\": qas}]})\n",
        "  raw_data[\"data\"] = data\n",
        "  return raw_data\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iClbtD2Jn4Iw",
        "outputId": "f70d8b01-5e0b-4cc6-c50a-6c88e6dd6831"
      },
      "source": [
        "print(samples_to_squad_json(test_samples))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': [{'title': '', 'paragraphs': [{'context': \"The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that were necessary for the success of the Apollo missions. Apollo used Saturn family rockets as launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three manned missions in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the Soviet Union in 1975.\", 'qas': [{'id': 'Q1', 'question': 'What project put the first Americans into space?', 'answers': [{'text': 'Project Mercury', 'answer_start': 361}], 'is_impossible': False}, {'id': 'Q2', 'question': 'What program was created to carry out these projects and missions?', 'answers': [{'text': 'Apollo', 'answer_start': 4}], 'is_impossible': False}, {'id': 'Q3', 'question': 'What year did the first manned Apollo flight occur?', 'answers': [{'text': '1968', 'answer_start': 740}], 'is_impossible': False}, {'id': 'Q4', 'question': 'What President is credited with the original notion of putting Americans in space?', 'answers': [{'text': 'John F. Kennedy', 'answer_start': 457}], 'is_impossible': False}, {'id': 'Q5', 'question': 'Who did the U.S. collaborate with on an Earth orbit mission in 1975?', 'answers': [{'text': 'Soviet Union', 'answer_start': 1288}], 'is_impossible': False}, {'id': 'Q6', 'question': 'How long did Project Apollo run?', 'answers': [{'text': '1961 to 1972', 'answer_start': 762}], 'is_impossible': False}, {'id': 'Q7', 'question': 'What program helped develop space travel techniques that Project Apollo used?', 'answers': [{'text': 'Gemini', 'answer_start': 874}], 'is_impossible': False}, {'id': 'Q8', 'question': 'What space station supported three manned missions in 1973-1974?', 'answers': [{'text': 'Skylab', 'answer_start': 1143}], 'is_impossible': False}, {'id': 'Q9', 'question': 'Trees?', 'answers': [{'text': 'The Apollo program', 'answer_start': 0}], 'is_impossible': False}]}]}]}\n"
          ]
        }
      ]
    }
  ]
}